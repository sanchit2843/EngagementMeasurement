{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>frameid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000181015</td>\n",
       "      <td>4000181015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4018350115</td>\n",
       "      <td>4018350115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4140810254</td>\n",
       "      <td>3100692035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100642019</td>\n",
       "      <td>3100742055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1813740233</td>\n",
       "      <td>1813740233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3100741017</td>\n",
       "      <td>3100741017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2100571047</td>\n",
       "      <td>2100571047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000181032</td>\n",
       "      <td>1100072083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1100172012</td>\n",
       "      <td>1100172012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3422270135</td>\n",
       "      <td>3422270135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ClipID     frameid label\n",
       "0  4000181015  4000181015     1\n",
       "1  4018350115  4018350115     1\n",
       "2  4140810254  3100692035     0\n",
       "3  3100642019  3100742055     0\n",
       "4  1813740233  1813740233     1\n",
       "5  3100741017  3100741017     1\n",
       "6  2100571047  2100571047     1\n",
       "7  4000181032  1100072083     0\n",
       "8  1100172012  1100172012     1\n",
       "9  3422270135  3422270135     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv('TrainLabels.csv')\n",
    "data = data['ClipID']\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i][:-4]\n",
    "data = data.to_frame()\n",
    "#Matched pair label\n",
    "data.insert(1,'frameid',data)\n",
    "data1 = data.copy()\n",
    "data1['frameid'] = np.random.permutation(data1['frameid'].values)\n",
    "data.insert(2,'label',1)\n",
    "data1.insert(2,'label',0)\n",
    "\n",
    "data1 = data1.iloc[:,:].values\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if(data1[i,0]==data1[i,1]):\n",
    "        data1[i,2] = 1\n",
    "data1 = pd.DataFrame(data1)\n",
    "data1.columns = ['ClipID','frameid','label']\n",
    "data = data.append(data1)\n",
    "data = shuffle(data)\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'],axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjaymoto75/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './frames/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2\n",
    "import sys\n",
    "im_size = 224\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor()])\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self,frame_dir,train_csv,sequence_length = 60,transform = None):\n",
    "        self.clip = train_csv['ClipID']\n",
    "        self.frameid = train_csv['frameid']\n",
    "        self.label = train_csv['label']\n",
    "        self.frame_dir = frame_dir\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.skip_length = int(300/sequence_length)\n",
    "    def __len__(self):\n",
    "        return len(self.frameid)\n",
    "    def __getitem__(self,idx):\n",
    "        id_1 = self.clip[idx][:6]\n",
    "        path1 = os.path.join(self.frame_dir,id_1)\n",
    "        path2 = os.path.join(path1,self.clip[idx])\n",
    "        id_2 = self.frameid[idx][:6]\n",
    "        path3 = os.path.join(self.frame_dir,id_2)\n",
    "        path4 = os.path.join(path3,self.frameid[idx])\n",
    "        seq_image = list()\n",
    "        i = 0\n",
    "        while i<300:\n",
    "            path3 = os.path.join(path2,str(i)+'.jpg')\n",
    "            image = cv2.imread(path3)\n",
    "            if(self.transform):\n",
    "                image = self.transform(image)\n",
    "            seq_image.append(image)\n",
    "            i = i+self.skip_length\n",
    "        seq_image = torch.stack(seq_image)\n",
    "        lb = self.label[idx]\n",
    "        seq_image = seq_image.reshape(3,self.sequence_length,im_size,im_size)\n",
    "        image = cv2.imread(os.path.join(path4,'10.jpg'))\n",
    "        if(self.transform):\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        return seq_image,image,lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.4889, 0.4887, 0.4891]\n",
    "std = [0.2074, 0.2074, 0.2074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.RandomRotation(degrees=10),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        #transforms.RandomRotation(degrees=10),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "train_data = video_dataset(data_path,data,transform = train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size = 4,num_workers = 4 ,shuffle = True)\n",
    "dataloaders = {'train':train_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model t3d\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "__all__ = ['DenseNet', 'densenet121', 'densenet161'] # with DropOut\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm3d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv3d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv3d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv3d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet3D(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "    \"\"\"\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
    "\n",
    "        super(DenseNet3D, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv3d(3, num_init_features, kernel_size=(3, 7, 7), stride=2, padding=(1, 3, 3), bias=False)),\n",
    "            ('norm0', nn.BatchNorm3d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm3d(num_features))\n",
    "        # Linear layer\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        return features\n",
    "    \n",
    "\n",
    "def densenet121_3D():\n",
    "    model = DenseNet3D(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16))\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet121_3D_DropOut():\n",
    "    model = DenseNet3D(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), drop_rate=0.2)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet169_3D():\n",
    "    model = DenseNet3D(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32))\n",
    "    return model\n",
    "\n",
    "\n",
    "# the below model has the lowest Top-1 error in ImageNet Data Set:\n",
    "def densenet161_3D():\n",
    "    model = DenseNet3D(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24))\n",
    "    return model\n",
    "\n",
    "\n",
    "# the below model has the lowest Top-1 error in ImageNet Data Set:\n",
    "def densenet161_3D_DropOut():\n",
    "    model = DenseNet3D(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24), drop_rate=0.2)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet201_3D():\n",
    "    model = DenseNet3D(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32))\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet121(**kwargs):\n",
    "    \"\"\"Constructs a DenseNet-121_DropOut model.\n",
    "    \"\"\"\n",
    "    model = DenseNet3D(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), drop_rate=0.2, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet161(**kwargs):\n",
    "    \"\"\"Constructs a DenseNet-161_DropOut model.\n",
    "    \"\"\"\n",
    "    model = DenseNet3D(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24), drop_rate=0.2, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "from torchvision import models\n",
    "class classifie(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifie, self).__init__()\n",
    "        self.cnn_arch = models.densenet121(pretrained = True)\n",
    "        self.linear = nn.Linear(2048, 1024)\n",
    "        self.model = self.cnn_arch.features\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        avg_pool = nn.functional.adaptive_avg_pool2d(out, output_size = 1)\n",
    "        batch = out.shape[0]\n",
    "        out = avg_pool.view(batch, -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3d = densenet121_3D_DropOut().to('cuda')\n",
    "t3d = nn.DataParallel(t3d)\n",
    "linear = nn.Linear(2048,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifie().to('cuda')\n",
    "classifier = nn.DataParallel(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from Modular_code.clr import *\n",
    "writer = SummaryWriter()\n",
    "device = 'cuda'\n",
    "cls_criterion = nn.CrossEntropyLoss().to(device)\n",
    "params = list(t3d.parameters()) + list(classifier.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "num_epochs = 5\n",
    "onecyc = OneCycle(len(train_loader)*num_epochs,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1 ---\n",
      "\n",
      "--- Phase train ---\n",
      "[Epoch 1/5] [Batch 2678/2679] [Loss: 0.750674 (0.701616), Acc: 0.00% (49.98%)]]]\n",
      "train , acc: 49.98133631952221\n",
      "\n",
      "--- Epoch 2 ---\n",
      "\n",
      "--- Phase train ---\n",
      "[Epoch 2/5] [Batch 1490/2679] [Loss: 0.682977 (0.698085), Acc: 75.00% (49.66%)]]"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "iteration = 0\n",
    "linear = nn.Linear(2048,2).cuda()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    print('')\n",
    "    print(f\"--- Epoch {epoch} ---\")\n",
    "    phase1 = dataloaders.keys()\n",
    "    acc_all = list()\n",
    "    loss_all = list()\n",
    "    for phase in phase1:\n",
    "        print('')\n",
    "        print(f\"--- Phase {phase} ---\")\n",
    "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
    "        for batch_i, (X,x1, y) in enumerate(dataloaders[phase]):\n",
    "            iteration = iteration+1\n",
    "            image_sequences = Variable(X.to(device), requires_grad=True)\n",
    "            image = Variable(x1.to(device), requires_grad=True)\n",
    "            labels = Variable(y.to(device), requires_grad=False)\n",
    "            optimizer.zero_grad()\n",
    "            #model.lstm.reset_hidden_state()\n",
    "            features = t3d(image_sequences)\n",
    "            out = F.relu(features, inplace=True)\n",
    "            avg_pool = nn.functional.adaptive_avg_pool3d(out, output_size = 1)\n",
    "            batch = out.shape[0]\n",
    "            o1 = avg_pool.view(batch, -1)\n",
    "            o2 = classifier(image)\n",
    "            inp = torch.cat((o1,o2),1)\n",
    "            predictions = linear(inp)\n",
    "            loss = cls_criterion(predictions, labels)\n",
    "            acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_metrics[\"loss\"].append(loss.item())\n",
    "            epoch_metrics[\"acc\"].append(acc)\n",
    "            if(phase=='train'):\n",
    "                lr,_ = onecyc.calc()\n",
    "                update_lr(optimizer, lr)\n",
    "            batches_done = epoch * len(dataloaders[phase]) + batch_i\n",
    "            batches_left = num_epochs * len(dataloaders[phase]) - batches_done\n",
    "\n",
    "            sys.stdout.write(\n",
    "                    \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n",
    "                    % (\n",
    "                        epoch,\n",
    "                        num_epochs,\n",
    "                        batch_i,\n",
    "                        len(dataloaders[phase]),\n",
    "                        loss.item(),\n",
    "                        np.mean(epoch_metrics[\"loss\"]),\n",
    "                        acc,\n",
    "                        np.mean(epoch_metrics[\"acc\"]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Empty cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            if(phase=='train'):\n",
    "                writer.add_scalar('data/acc',np.mean(epoch_metrics[\"acc\"]) ,iteration)\n",
    "                writer.add_scalar('data/loss',np.mean(epoch_metrics[\"loss\"]) , iteration)\n",
    "                acc_all.append(np.mean(epoch_metrics[\"acc\"]))\n",
    "                loss_all.append(np.mean(epoch_metrics[\"loss\"]))\n",
    "            if(phase=='val'):\n",
    "                writer.add_scalar('data/valacc',np.mean(epoch_metrics[\"acc\"]) , iteration)\n",
    "                writer.add_scalar('data/valloss',np.mean(epoch_metrics[\"loss\"]) , iteration)\n",
    "        print('')\n",
    "        print('{} , acc: {}'.format(phase,np.mean(epoch_metrics[\"acc\"])))\n",
    "        if(phase=='train'):\n",
    "\n",
    "            acc_all.append(np.mean(epoch_metrics[\"acc\"]))\n",
    "            loss_all.append(np.mean(epoch_metrics[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t3d.module.state_dict(),('./t3dpre5.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
